{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for using Forest to analyze Beiwe data. We will first download the data using mano. We will also be creating some time series plots using the generated statistic summaries. There are four parts to this tutorial.\n",
    "\n",
    "1. Check Python version and download Forest.\n",
    "2. Download data for your study from the server.\n",
    "3. Process data using forest.\n",
    "4. Creating time series plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Python Version and Download Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, we need to check the current distribution of Python. Note that forest is built using Python 3.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the python version and the path to the Python interpreter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(python_version()) ## Prints your version of python\n",
    "print(sys.executable) ## Prints your current python installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output should display two lines.* \n",
    "\n",
    "1. The Python version installed- make sure you are not using a version of Python that is earlier than 3.8\n",
    "2. The path to where Python is currently installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may need to install git, pip, mano and forest. To do so, enter the lines below in a command-line shell. If not, you can skip to the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conda install git pip`\n",
    "\n",
    "`pip install mano`\n",
    "\n",
    "`pip install https://github.com/onnela-lab/forest/tarball/develop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Beiwe Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will download data from a beiwe study. Edit the cell below to match parameters in your study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **study_id**, enter the \"study ID, found in the top right corner of the study page\". \n",
    "- For **dest_dir**, enter the \"path to the folder you want raw data stored in\". \n",
    "- For **server**, enter the server where data is located. If your Beiwe website URL starts with studies.beiwe.org, enter \"studies\"\n",
    "- For **time_start**, enter the earliest date you want to download data for, in YYYY-MM-DD format.\n",
    "- For **time_end**, enter the latest date you want to download data for, in YYYY-MM-DD format. If this is None, mano will download all data available (up until today at midnight). \n",
    "- For **data_streams**, enter a list of data streams you want to download. Forest currently analyzes `gps`, `survey_timings`, `calls`, and `texts` data streams. A full list of data types can be found under the \"Download Data\" tab of the Beiwe website. If this is None, all possible data streams will be downloaded. \n",
    "- For **beiwe_ids**, enter a list of Beiwe IDs you want to download data for. If you leave this as an empty list, mano will attempt to download data for all user IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = \"\"\n",
    "dest_dir = \"raw_data\"\n",
    "server = \"studies\"\n",
    "time_start = \"2008-01-01\"\n",
    "time_end = None\n",
    "data_streams = [\"gps\", \"survey_timings\", \"survey_answers\", \"calls\", \"texts\"]\n",
    "beiwe_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we will define a function that iterates through Beiwe IDs and downloads desired data for each ID. This function also retries downloading data when a network failure occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mano\n",
    "import mano.sync as msync\n",
    "import requests\n",
    "from datetime import datetime\n",
    "def download_data(keyring,  study_id, download_folder, users = [], time_start = \"2008-01-01\", \n",
    "                      time_end = None, data_streams = None):\n",
    "    '''\n",
    "    Downloads all data for specified users, time frame, and data streams. \n",
    "    \n",
    "    This function downloads all data for selected users, time frame, and data streams, and writes them to an \n",
    "    output folder, with one subfolder for each user, and subfolders inside the user's folder for each data stream. \n",
    "    If a server failure happens, the function re-attempts the download. \n",
    "    \n",
    "    Args: \n",
    "        keyring: a keyring generated by mano.keyring\n",
    "    \n",
    "        users(iterable): A list of users to download data for. If none are entered, it attempts to download data for all users\n",
    "        \n",
    "        study_id(str): The id of a study\n",
    "        \n",
    "        download_folder(str): path to a folder to download data\n",
    "        \n",
    "        time_start(str): The initial date to download data (Formatted in YYYY-MM-DD). Default is 2008-01-01, which is \n",
    "            before any Beiwe data existed.\n",
    "        \n",
    "        time_end(str): The date to end downloads. The default is today at midnight.\n",
    "        \n",
    "        data_streams(iterable): A list of all data streams to download. The default (None) is all possible data streams. \n",
    "        \n",
    "    '''\n",
    "    if study_id == \"\":\n",
    "        print(\"Error: Study ID is blank\")\n",
    "        return\n",
    "        \n",
    "    if (keyring['USERNAME'] == \"\" or keyring['PASSWORD'] == \"\" \n",
    "        or keyring[\"ACCESS_KEY\"] == \"\" or keyring[\"SECRET_KEY\"] == \"\"):\n",
    "        print(\"Error: Did you set up the keyring_studies.py file?\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.isdir(download_folder):\n",
    "        os.mkdir(download_folder)\n",
    "    \n",
    "    if time_end is None:\n",
    "        time_end = datetime.today().strftime(\"%Y-%m-%d\")+\"T23:59:00\"\n",
    "        \n",
    "    if users == []:\n",
    "        print('Obtaining list of users...')\n",
    "        num_tries = 1\n",
    "        while num_tries < 5:\n",
    "            try:\n",
    "                users = [u for u in mano.users(keyring, study_id)]\n",
    "                num_tries = 6\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Someone closed the program\")\n",
    "                sys.exit()\n",
    "            except:\n",
    "                num_tries = num_tries + 1\n",
    "    \n",
    "    for u in users:\n",
    "        zf = None\n",
    "        download_success = False\n",
    "        num_tries = 0\n",
    "        while not download_success:\n",
    "            try:\n",
    "                print(f'Downloading data for {u}')\n",
    "                zf = msync.download(keyring, study_id, u, data_streams, time_start = time_start, time_end = time_end)\n",
    "                if zf is not None:\n",
    "                    zf.extractall(download_folder)\n",
    "                download_success = True\n",
    "            except requests.exceptions.ChunkedEncodingError:\n",
    "                print(f'Network failed in download of {u}, try {num_tries}')\n",
    "                num_tries = num_tries + 1\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Someone closed the program\")\n",
    "                sys.exit()\n",
    "            except: \n",
    "                print(f'Network failed in download of {u}, try {num_tries}')\n",
    "                num_tries = num_tries + 1\n",
    "            if num_tries > 5:\n",
    "                download_success = True\n",
    "                print(f\"Too many failures; skipping user {u}\")\n",
    "        if zf is None:\n",
    "            print(f'No data for {u}; nothing written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next cell, we will import our keyring_studies.py file which includes download credentials. If you haven't already done this, open the keyring_studies.py file and paste your credentials inside. \n",
    "\n",
    "If your keyring_studies.py file is in a different directory than the one which includes this notebook, replace `sys.path.insert(0, '')` with `sys.path.insert(0, 'path/to/dir/containing/file/')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import .py file located in another directory if needed\n",
    "sys.path.insert(0, '')\n",
    "\n",
    "import keyring_studies\n",
    "kr = mano.keyring(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will download your data. Downloading your data will probably be the most time-consuming part of the whole process, so if you've already downloaded the data, you will save time by not running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(kr, study_id, dest_dir, beiwe_ids, time_start, time_end, data_streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data using Forest \n",
    "- Using the Forest library developed by the Onnela lab, we compute daily GPS and communication summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate the GPS-related summary statistics by using the **gps_stats_main** function under the **traj2stat.py** in the Jasmine tree of Forest. This code will take between 15 minutes to 12 hours to run, depending on your machine and the quantity of data downloaded. To make sure that everything is working right, change the `beiwe_ids` argument from `None` to a list with just a couple of the Beiwe IDs in your study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **data_dir**, enter the \"path to the data file directory\". \n",
    "- For **output_dir**, enter the \"path to the file directory where output is to be stored\". \n",
    "- For **tz_str**, enter the time zone where the study was conducted. Here, it's **\"America/New_York.\"** We can use \"pytz.all_timezones\" to check all options.\n",
    "- For **options**, there are 'daily' or 'hourly' or 'both' for the temporal resolution for summary statistics. Here, we chose **\"daily.\"**\n",
    "- For **save_traj**, it's \"True\" if you want to save the trajectories as a csv file, \"False\" if you don't (default: False). Here, we chose **\"True.\"**\n",
    "- For **beiwe_ids**, enter the list of Beiwe IDs to run Forest on. If this is `None`, jasmine will run on all users in the data_dir directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forest.jasmine.traj2stats\n",
    "\n",
    "data_dir = dest_dir\n",
    "output_dir = \"gps_output\"\n",
    "tz_str = \"America/New_York\"\n",
    "option = \"daily\"\n",
    "save_traj = True \n",
    "beiwe_ids = None\n",
    "\n",
    "\n",
    "forest.jasmine.traj2stats.gps_stats_main(\n",
    "    data_dir, output_dir, tz_str, option, save_traj, participant_ids = beiwe_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output should describe how the data is being processed. If this is working correctly, you will see something like:*\n",
    "    \n",
    "><i>User: tcqrulfj  \n",
    "Read in the csv files ...  \n",
    "Collapse data within 10 second intervals ...  \n",
    "Extract flights and pauses ...  \n",
    "Infer unclassified windows ...  \n",
    "Merge consecutive pauses and bridge gaps ...  \n",
    "Selecting basis vectors ...  \n",
    "Imputing missing trajectories ...  \n",
    "Tidying up the trajectories...  \n",
    "Calculating the daily summary stats...<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we compute the call and text-based summary statistics by using the **log_stats_main** function under the **log_stats.py** in the Willow tree of Forest. This should run a lot faster than `forest.jasmine.traj2stats.gps_stats_main`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **data_dir**, enter the \"path to the data file directory\". \n",
    "- For **output_dir**, enter the \"path to the file directory where output is to be stored\". \n",
    "- For **tz_str**, enter the time zone where the study was conducted. Here, it's **\"America/New_York.\"** \n",
    "- For **options**, it's 'daily' or 'hourly' or 'both' for the temporal resolution for summary statistics. Here, we chose **\"daily.\"**\n",
    "- For **beiwe_ids**, enter the list of Beiwe IDs to run Forest on. If this is `None`, willow will run on all users in the data_dir directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forest.willow.log_stats\n",
    "data_dir = dest_dir\n",
    "output_dir = \"comm_output\"\n",
    "tz_str = \"America/New_York\"\n",
    "option = \"daily\"\n",
    "beiwe_ids = None\n",
    "\n",
    "\n",
    "\n",
    "forest.willow.log_stats.log_stats_main(\n",
    "    data_dir, output_dir, tz_str, option, beiwe_id = beiwe_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output should describe how the data is being processed (e.g., read, collapse, extracted...imputing, tidying, and calculating daily summary stats).*\n",
    "\n",
    ">*Note- calls and texts data are only collected on Android phones. If you only enrolled users with iPhones in your study, you will not have any output here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of **gps_stats_main** and **log_stats_main** are generated with respect to each suject in the study folder (there is one csv file per subject). For further use, it is often convenient to concatenate these csv files into one file containing data for all users in the study. \n",
    "\n",
    "- The following code is  used to concatenate these files into a single csv for the **GPS summaries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta  \n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "# Path to subdirectory\n",
    "direc = os.getcwd()\n",
    "data_dir = os.path.join(direc,\"gps_output\")\n",
    "\n",
    "# initialize dataframe list\n",
    "df_list = []\n",
    "\n",
    "# loop through all directories - select folder\n",
    "for subdir, dirs, files in os.walk(data_dir):\n",
    "    \n",
    "    # loop through files in list\n",
    "    for file in files:\n",
    "        # obtain subject study_id \n",
    "        file_dir = os.path.join(data_dir,file)\n",
    "        subject_id = os.path.basename(file_dir)[:-4]\n",
    "        if file[-4:] == \".csv\":# only read in csv files\n",
    "            temp_df = pd.read_csv(file_dir)\n",
    "            temp_df.insert(loc=0, column=\"Date\", value=pd.to_datetime(temp_df[['day', 'month', 'year']]))\n",
    "            temp_df.insert(loc=0, column='Beiwe_ID', value=subject_id)\n",
    "            df_list.append(temp_df)\n",
    "            \n",
    "if len(df_list) > 0:\n",
    "                \n",
    "    # concatenate dataframes within list --> Final Data for trajectories\n",
    "    response_data = pd.concat(df_list, axis=0).reset_index()\n",
    "    response_data = response_data.drop(['index','day', 'month', 'year'], axis=1)\n",
    "\n",
    "    # print few few observations\n",
    "    print(response_data.head())\n",
    "\n",
    "    # Write results to CSV \n",
    "    response_filename = 'gps_summary.csv'\n",
    "\n",
    "    path_resp = os.path.join(direc, response_filename)    \n",
    "\n",
    "    # write to csv\n",
    "    response_data.to_csv(path_resp, index=False)\n",
    "else:\n",
    "    print(\"Error: No data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output should show the data for the first five observations in the concatenated dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following code is  used to concatenate these files into a single csv for the **communication summaries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (use study_id and timestamp)\n",
    "# Path to subdirectory\n",
    "direc = os.getcwd()\n",
    "data_dir = os.path.join(direc,\"comm_output\")\n",
    "\n",
    "\n",
    "# initialize dataframe list\n",
    "df_list = []\n",
    "\n",
    "# loop through all directories - select folder\n",
    "for subdir, dirs, files in os.walk(data_dir):\n",
    "    \n",
    "    # loop through files in list\n",
    "    for file in files:\n",
    "        # obtain patient study_id \n",
    "        file_dir = os.path.join(data_dir,file)\n",
    "        print(file_dir)\n",
    "        subject_id = os.path.basename(file_dir)[:-4]\n",
    "        if file[-4:] == \".csv\":\n",
    "            temp_df = pd.read_csv(file_dir)\n",
    "            temp_df.insert(loc=0, column=\"Date\", value=pd.to_datetime(temp_df[['day', 'month', 'year']]))\n",
    "            temp_df.insert(loc=0, column='Beiwe_ID', value=subject_id)\n",
    "            df_list.append(temp_df)\n",
    "                \n",
    "# concatenate dataframes within list --> Final Data for trajectories\n",
    "if len(df_list) > 0:\n",
    "    response_data = pd.concat(df_list, axis=0).reset_index()\n",
    "    response_data = response_data.drop(['index','day', 'month', 'year'], axis=1)\n",
    "\n",
    "    # print few few observations\n",
    "    print(response_data.head())\n",
    "\n",
    "    # Write results to CSV \n",
    "    response_filename = 'comm_summary.csv'\n",
    "\n",
    "    path_resp = os.path.join(direc, response_filename)    \n",
    "\n",
    "    # write to csv\n",
    "    response_data.to_csv(path_resp, index=False)\n",
    "else:\n",
    "    print(\"Error: No data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output should show the data for the first five observations in the concatenated dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we summarize survey information using the **survey_stats_main** function under the **base.py** in the Sycamore tree of Forest. This will take between 5 minutes and 2 hours to run, depending on how many surveys were administered durinng your study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **data_dir**, enter the \"path to the data file directory\". \n",
    "- For **output_dir**, enter the \"path to the file directory where output is to be stored\". \n",
    "- For **tz_str**, enter the time zone where the study was conducted. Here, it's **\"America/New_York.\"** \n",
    "- For **beiwe_ids**, enter the list of Beiwe IDs to run Forest on. If this is `None`, sycamore will run on all users in the data_dir directory.\n",
    "- For **config_path**, enter the filepath to your downloaded survey config file. This can be downloaded by clicking \"edit study\" on your study page, and clicking \"Export study settings JSON file under \"Export/Import study settings\". If this is None, Sycamore will still run, but fewer outputs will be produced. \n",
    "- For **interventions_filepath**, enter the filepath to your downloaded interventions timing file. This can be downloaded by clicking \"edit study\" on your study page, and clicking \"Download Interventions\" next to \"Intervention Data\". If this is None, Sycamore will still run, but fewer outputs will be produced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest.sycamore.base import survey_stats_main\n",
    "\n",
    "data_dir = dest_dir\n",
    "output_dir = \"survey_output\"\n",
    "tz_str = \"America/New_York\"\n",
    "beiwe_ids = None\n",
    "config_path = None\n",
    "interventions_filepath = None\n",
    "\n",
    "survey_stats_main(\n",
    "    data_dir, output_dir, tz_str, beiwe_ids, time_start, time_end,\n",
    "                 config_path, interventions_filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will also be generate some time series plots using the generated statistic summaries.\n",
    "- To read the file, we need to define **response_filename** with the concatenated dataset. Here, we are using 'gps_summary.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "direc = os.getcwd()\n",
    "response_filename = 'gps_summary.csv'\n",
    "path_resp = os.path.join(direc, response_filename)    \n",
    "\n",
    "# read data\n",
    "response_data = pd.read_csv(path_resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be sorted according to date. The following code will sort and create 4 even time intervals in the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure the data is sorted according to date\n",
    "response_data.sort_values('Date', inplace = True)\n",
    "response_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "def time_series_plot(var_to_plot, ylab = '', xlab = 'Date', num_x_ticks = 4):\n",
    "    for key, grp in response_data.groupby(['Beiwe_ID']):\n",
    "        plt.plot(response_data.Date, response_data[var_to_plot], label=key)\n",
    "    \n",
    "    #if len(response_data['Beiwe_ID'].unique()) > 1: ## more than one user to plot\n",
    "    #    plt.plot(response_data.Date, response_data[var_to_plot], c=response_data['Beiwe_ID'].astype('category'))\n",
    "    #else:\n",
    "    #    plt.plot(response_data.Date, response_data[var_to_plot]) #just one user\n",
    "    title = f\"Time Series Plot of {var_to_plot}\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    \n",
    "    ## get evenly indices\n",
    "    tick_indices = [(i * (len(response_data.Date.unique()) - 1)) // (num_x_ticks - 1) for i in range(num_x_ticks) ]\n",
    "    \n",
    "    plt.xticks(response_data.Date.unique()[tick_indices])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can now create time series plots using **time_series_plot('variable')**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_plot('dist_traveled', ylab = \"km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output displays a time series plot for the variable, \"dist_traveled.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_plot('sd_flight_length', ylab = \"km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The output displays a time series plot for the variable, \"sd_flight_length.\"*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "current_develop",
   "language": "python",
   "name": "current_develop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
